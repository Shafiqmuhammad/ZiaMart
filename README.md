"# ZiaMart" 
![image](https://github.com/user-attachments/assets/c837c6b9-9ecd-4f5a-8d67-bcf6f64a221b)

## Overview
An architecture diagram for "Zia Mart" Here's a breakdown based on the image:

- Customer: The end user of the platform, interacting with the services through the Kong Gateway.

- Kong Gateway: Handles API request routing, authentication, rate-limiting, and exposes each microservice's API. It acts as the single entry point for external consumers.

- Services: This is the main processing layer, with each service being a standalone component, containerized using Docker.

    - Services communicate with each other through Kafka for event streaming and Dapr for service invocation and state management.
- Microservices: Under the services layer, you have different microservices handling specific domains:

   - Users
   - Product
   - Order
   - Inventory
   - Notification
   - Payment

- Kafka: Used for event streaming, likely for real-time data communication between the services.

The overall architecture follows a microservices pattern with an API Gateway (Kong) and event-driven communication (Kafka and Dapr). It looks like you're building an event-driven microservices architecture with good modularity and scalability.

## Structure of Users Service 
complete updated structure for the services/users/ microservice with Kafka, Protobuf, PostgreSQL, FastAPI, and Docker. The files will now include Protobuf for Kafka message serialization.

services/
└── users/
    ├── Dockerfile
    ├── pyproject.toml
    ├── poetry.lock
    ├── app/
    │   ├── main.py
    │   ├── routes/
    │   │   └── user_routes.py
    │   ├── models/
    │   │   └── user.py
    │   ├── services/
    │   │   └── user_service.py
    │   ├── repositories/
    │   │   └── user_repository.py
    │   ├── events/
    │   │   └── user_events.py
    │   ├── protobuf/
    │   │   └── user_pb2.py (Generated by protoc from user.proto)
    │   ├── kafka_utils.py
    │   └── config/
    │       └── settings.py
    ├── tests/
    │   └── test_user_service.py
    └── protobuf/
        └── user.proto


### Step 1: Create a users service 
```
poetry new users
```
### Step 2: Create a Dockerfile

### Step 3: Update toml file 

### Step 4: Create file users/user/main.py

### Step 5: create file routes 
users/routes/user_routes.py


### Step 6: create a file users/models/user.py

### Step 7: create a file users/services/user_service.py 

### Step 8: create a file users/repositories/user_repository.py 

### Step 9: create a file users/prouducer/user_events.py 

### Step 10: create a file users/consumer/kafka_utils.py

### Step 11: create a file users/protobuf/user.proto
```
protoc --proto_path=. --python_out=. user.proto
```

### Step : 

### Step : 


### Protobuf for Kafka Serialization
You can continue using Protobuf to serialize and deserialize messages in Kafka. Here’s how you can use Protobuf in your Kafka producers and consumers.

Producer (in app/events/user_events.py)

Consumer (in app/kafka_utils.py)

- **Protobuf Serialization:** Both producer and consumer use Protobuf for serializing and deserializing messages sent through Kafka





